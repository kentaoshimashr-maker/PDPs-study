{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa1f24b4-cf1b-47ec-911f-0628b324c4b3",
   "metadata": {},
   "source": [
    "# PDP-based Feature Engineering for Wine Quality (Kaggle WineQT)\r\n",
    "# ワイン品質予測におけるPDP特徴変換の検証（Kaggle WineQTデータ使用）\r\n",
    "\r\n",
    "This notebook performs feature engineering based on Partial Dependence Plots (PDP) to improve linear regression performance on the Wine Quality dataset from Kaggle.\r\n",
    "\r\n",
    "このノートブックでは、KaggleのWine Qualityデータセットを使い、PDPに基づく特徴変換で線形回帰の精度向上を試みます。\r\n",
    "## Setup\r\n",
    "\r\n",
    "### 1. Install dependencies\r\n",
    "\r\n",
    "Run in your environment:dependencies:  results/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5385428-b611-4a5c-a54f-b8354d21f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas scikit-learn xgboost matplotlib scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f17d3a3-d9c4-464a-8375-d0603e31a15d",
   "metadata": {},
   "source": [
    "### 2. Prepare data\r\n",
    "\r\n",
    "Download the dataset from Kaggle:  \r\n",
    "https://www.kaggle.com/datasets/yasserh/wine-quality-dataset\r\n",
    "\r\n",
    "Place `WineQT.csv` into the `data/` folder relative to this notebook.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Load libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b12079-a6bf-477c-a4ff-e1eefe025f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"data/WineQT.csv\")  # Adjust path if needed\n",
    "df = df.drop(columns=['Id'])\n",
    "\n",
    "X = df.drop(columns=['quality'])\n",
    "y = df['quality']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1785aa72-2ea5-44a6-bcf1-d87e068bcdfc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Define baseline and advanced models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da375cd-c73c-4bf5-8037-6a96f7b72292",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Linear Regression (Baseline)\": LinearRegression(),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, random_state=42, verbosity=0),\n",
    "    \"MLP (Neural Network)\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if \"Linear\" in name:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    results[name] = {\"R2\": r2, \"RMSE\": rmse, \"model\": model}\n",
    "    print(f\"{name} R2: {r2:.4f}, RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e9630-f654-4a45-b836-bf2677a896e1",
   "metadata": {},
   "source": [
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Define candidate transformation functions used for PDP fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba7b22-0b3f-43da-b90a-05fd70f2bf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, a, b): return a * x + b\n",
    "def f2(x, a, b, c): return a * x**2 + b * x + c\n",
    "def f3(x, a, b, c, d): return a * x**3 + b * x**2 + c * x + d\n",
    "def flog(x, a, b): return a * np.log(x + 1e-9) + b\n",
    "\n",
    "monotonic_functions = [f1, f2, f3, flog]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675bb4db-6fb7-4a72-98c5-be86fb68aa3d",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Function to transform features with PDP-based fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6344c3-36c8-449f-b422-bf2119019645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_features(base_model, X_data, feature_names, functions):\n",
    "    best_functions = {}\n",
    "    for feature in feature_names:\n",
    "        try:\n",
    "            fig, ax = plt.subplots()\n",
    "            display = PartialDependenceDisplay.from_estimator(base_model, X_data, [feature], ax=ax)\n",
    "            plt.close(fig)\n",
    "\n",
    "            pd_dict = display.pd_results[0]\n",
    "            x_pd = np.array(pd_dict['grid_values']).ravel()\n",
    "            y_pd = np.array(pd_dict['average']).ravel()\n",
    "\n",
    "            mse_best = np.inf\n",
    "            best_fn, best_popt = None, None\n",
    "\n",
    "            for fn in functions:\n",
    "                try:\n",
    "                    p0 = np.ones(fn.__code__.co_argcount - 1)\n",
    "                    popt, _ = curve_fit(fn, x_pd, y_pd, maxfev=20000, p0=p0)\n",
    "                    mse = np.mean((y_pd - fn(x_pd, *popt)) ** 2)\n",
    "                    if mse < mse_best:\n",
    "                        mse_best = mse\n",
    "                        best_fn, best_popt = fn, popt\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            if best_fn is not None:\n",
    "                best_functions[feature] = (best_fn, best_popt)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    X_transformed = pd.DataFrame(index=X_data.index)\n",
    "    for feature in feature_names:\n",
    "        if feature in best_functions:\n",
    "            fn, params = best_functions[feature]\n",
    "            vals = fn(X_data[feature], *params)\n",
    "            vals = np.clip(vals, -1e6, 1e6)\n",
    "            X_transformed[feature + \"_trans\"] = vals\n",
    "        else:\n",
    "            X_transformed[feature] = X_data[feature]\n",
    "\n",
    "    return X_transformed, best_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8087d48-b3dc-4c3e-b90f-f305bf8e3988",
   "metadata": {},
   "source": [
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Apply PDP-based transformation with base models and evaluate with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a7c7b-07f3-4ba7-91eb-6994fc053ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp_base_models = {\n",
    "    \"Random Forest\": results[\"Random Forest\"][\"model\"],\n",
    "    \"XGBoost\": results[\"XGBoost\"][\"model\"],\n",
    "    \"MLP (Neural Network)\": results[\"MLP (Neural Network)\"][\"model\"]\n",
    "}\n",
    "\n",
    "print(\"\\n--- PDP-based Feature Engineering Results ---\")\n",
    "final_results = {}\n",
    "for name, base_model in pdp_base_models.items():\n",
    "    X_train_transformed, _ = get_transformed_features(base_model, X_train, X_train.columns, monotonic_functions)\n",
    "    X_test_transformed, _ = get_transformed_features(base_model, X_test, X_test.columns, monotonic_functions)\n",
    "\n",
    "    scaler_t = StandardScaler()\n",
    "    X_train_t_scaled = scaler_t.fit_transform(X_train_transformed)\n",
    "    X_test_t_scaled = scaler_t.transform(X_test_transformed)\n",
    "\n",
    "    lr_final = LinearRegression()\n",
    "    lr_final.fit(X_train_t_scaled, y_train)\n",
    "    y_pred_final = lr_final.predict(X_test_t_scaled)\n",
    "\n",
    "    r2_final = r2_score(y_test, y_pred_final)\n",
    "    rmse_final = np.sqrt(mean_squared_error(y_test, y_pred_final))\n",
    "    final_results[name] = {\"R2\": r2_final, \"RMSE\": rmse_final}\n",
    "    print(f\"Linear Regression R2 with {name} PDP-transformed features: {r2_final:.4f}, RMSE: {rmse_final:.4f}\")\n",
    "\n",
    "# 3. 最終結果まとめ表示\n",
    "print(\"\\n--- Summary of R2 and RMSE Scores ---\")\n",
    "print(f\"Baseline Linear Regression R2: {results['Linear Regression (Baseline)']['R2']:.4f}, RMSE: {results['Linear Regression (Baseline)']['RMSE']:.4f}\")\n",
    "for name, score_dict in final_results.items():\n",
    "    print(f\"R2 and RMSE after {name} PDP-based transformation: R2={score_dict['R2']:.4f}, RMSE={score_dict['RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d70845-591d-49ab-bb56-8314db9c78c2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Visualize PDPs and their fitted approximation curves for comparative analysis and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55ff3a-57f5-4aff-8920-0efa085585d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_transformed_features(base_model, X_data, feature_names, functions):\n",
    "    best_functions = {}\n",
    "    for feature in feature_names:\n",
    "        try:\n",
    "            fig, ax = plt.subplots()\n",
    "            display = PartialDependenceDisplay.from_estimator(base_model, X_data, [feature], ax=ax)\n",
    "            plt.close(fig)\n",
    "\n",
    "            pd_dict = display.pd_results[0]\n",
    "            x_pd = np.array(pd_dict['grid_values']).ravel()\n",
    "            y_pd = np.array(pd_dict['average']).ravel()\n",
    "\n",
    "            mse_best = np.inf\n",
    "            best_fn, best_popt = None, None\n",
    "\n",
    "            for fn in functions:\n",
    "                try:\n",
    "                    p0 = np.ones(fn.__code__.co_argcount - 1)\n",
    "                    popt, _ = curve_fit(fn, x_pd, y_pd, maxfev=20000, p0=p0)\n",
    "                    mse = np.mean((y_pd - fn(x_pd, *popt)) ** 2)\n",
    "                    if mse < mse_best:\n",
    "                        mse_best = mse\n",
    "                        best_fn, best_popt = fn, popt\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "            if best_fn is not None:\n",
    "                best_functions[feature] = (best_fn, best_popt, (x_pd, y_pd))\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    X_transformed = pd.DataFrame(index=X_data.index)\n",
    "    for feature in feature_names:\n",
    "        if feature in best_functions:\n",
    "            fn, params = best_functions[feature][:2]\n",
    "            vals = fn(X_data[feature], *params)\n",
    "            vals = np.clip(vals, -1e6, 1e6)\n",
    "            X_transformed[feature + \"_trans\"] = vals\n",
    "        else:\n",
    "            X_transformed[feature] = X_data[feature]\n",
    "\n",
    "    return X_transformed, best_functions\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "best_functions_dicts = {}\n",
    "for name, base_model in pdp_base_models.items():\n",
    "    _, best_functions = get_transformed_features(base_model, X_train, feature_names, monotonic_functions)\n",
    "    best_functions_dicts[name] = best_functions\n",
    "\n",
    "for feature in feature_names:\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 4), sharey=True)\n",
    "    for idx, (model_name, best_functions) in enumerate(best_functions_dicts.items()):\n",
    "        ax = axs[idx]\n",
    "        if feature in best_functions:\n",
    "            fn, params = best_functions[feature][:2]\n",
    "            x_pd, y_pd = best_functions[feature][2]\n",
    "            ax.scatter(x_pd, y_pd, label='PDP', alpha=0.75)\n",
    "            y_fit = fn(x_pd, *params)\n",
    "            ax.plot(x_pd, y_fit, 'r--', label=f'Fit: {fn.__name__}')\n",
    "            ax.set_title(model_name)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, 'N/A', fontsize=12, ha='center', va='center')\n",
    "        ax.set_xlabel(feature)\n",
    "        if idx == 0:\n",
    "            ax.set_ylabel('Partial Dependence')\n",
    "        ax.legend()\n",
    "    plt.suptitle(f'PDP & Fit Comparison: {feature}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b9eaf-6df0-44ed-a56b-de9b2b387716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
